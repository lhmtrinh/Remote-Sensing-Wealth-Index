{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 13:55:58.171223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-29 13:55:58.171275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-29 13:55:58.172074: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-29 13:55:58.178396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 13:55:59.854743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import load_resnet_model\n",
    "import os\n",
    "from train_regression_weighted_loss_loaded import train_model\n",
    "import re\n",
    "from dataloader import create_dataloader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_resnet_model('resnet50', num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(directory):\n",
    "    \"\"\"\n",
    "    Get all file paths in the specified directory with the specified file extension.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): The directory to search for files.\n",
    "    - file_extension (str): The file extension to filter by.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of file paths.\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "# Use a regular expression to extract the batch number from the filename\n",
    "def extract_batch_number(file_path):\n",
    "    match = re.search(r\"data_batch_(\\d+)\", file_path)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return -1  # If for some reason a file doesn't match the pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(get_file_paths('./data/records/train/'), key= extract_batch_number)\n",
    "val_files = sorted(get_file_paths('./data/records/val/'), key= extract_batch_number)\n",
    "\n",
    "train_loaders = [create_dataloader(file, True, 64) for file in train_files]\n",
    "val_loaders = [create_dataloader(file, True, 64) for file in val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_labels = []\n",
    "# for train_loader in train_loaders:\n",
    "#     for _, labels in tqdm(train_loader):\n",
    "#         training_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "# dense_weight_model = DenseWeight(0.2)\n",
    "# dense_weight_model.fit(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 7.8966, Train R2: -41.7256, Val Loss: 7.8128, Val R2: -29.3358\n",
      "Model saved as checkpoint_epoch_1.pth\n",
      "Epoch 2/30, Train Loss: 7.4176, Train R2: -43.6122, Val Loss: 7.2808, Val R2: -21.8544\n",
      "Model saved as checkpoint_epoch_2.pth\n",
      "Epoch 3/30, Train Loss: 6.8743, Train R2: -44.9273, Val Loss: 6.7095, Val R2: -11.1641\n",
      "Model saved as checkpoint_epoch_3.pth\n",
      "Epoch 4/30, Train Loss: 6.2552, Train R2: -44.4586, Val Loss: 6.1948, Val R2: -7.4286\n",
      "Model saved as checkpoint_epoch_4.pth\n",
      "Epoch 5/30, Train Loss: 5.5952, Train R2: -38.6612, Val Loss: 5.4803, Val R2: -29.5711\n",
      "Model saved as checkpoint_epoch_5.pth\n",
      "Epoch 6/30, Train Loss: 4.8815, Train R2: -32.0050, Val Loss: 4.7429, Val R2: -10.6461\n",
      "Model saved as checkpoint_epoch_6.pth\n",
      "Epoch 7/30, Train Loss: 4.1490, Train R2: -26.3074, Val Loss: 3.9685, Val R2: -9.2214\n",
      "Model saved as checkpoint_epoch_7.pth\n",
      "Epoch 8/30, Train Loss: 3.4491, Train R2: -21.4182, Val Loss: 3.2659, Val R2: -4.8555\n",
      "Model saved as checkpoint_epoch_8.pth\n",
      "Epoch 9/30, Train Loss: 2.7812, Train R2: -14.3294, Val Loss: 2.6331, Val R2: -7.6983\n",
      "Model saved as checkpoint_epoch_9.pth\n",
      "Epoch 10/30, Train Loss: 2.1762, Train R2: -10.0428, Val Loss: 2.0579, Val R2: -6.6612\n",
      "Model saved as checkpoint_epoch_10.pth\n",
      "Epoch 11/30, Train Loss: 1.6695, Train R2: -6.8178, Val Loss: 1.6028, Val R2: -10.0677\n",
      "Model saved as checkpoint_epoch_11.pth\n",
      "Epoch 12/30, Train Loss: 1.3458, Train R2: -4.8932, Val Loss: 1.3414, Val R2: -1.3613\n",
      "Model saved as checkpoint_epoch_12.pth\n",
      "Epoch 13/30, Train Loss: 1.1036, Train R2: -2.6111, Val Loss: 1.0694, Val R2: -1.7183\n",
      "Model saved as checkpoint_epoch_13.pth\n",
      "Epoch 14/30, Train Loss: 0.7426, Train R2: -0.9207, Val Loss: 0.7109, Val R2: -0.4240\n",
      "Model saved as checkpoint_epoch_14.pth\n",
      "Epoch 15/30, Train Loss: 0.4565, Train R2: -0.1133, Val Loss: 0.4826, Val R2: -0.4591\n",
      "Model saved as checkpoint_epoch_15.pth\n",
      "Epoch 16/30, Train Loss: 0.3314, Train R2: -1.0584, Val Loss: 0.3912, Val R2: -0.4537\n",
      "Model saved as checkpoint_epoch_16.pth\n",
      "Epoch 17/30, Train Loss: 0.2907, Train R2: -0.5501, Val Loss: 0.3589, Val R2: -1.7312\n",
      "Model saved as checkpoint_epoch_17.pth\n",
      "Epoch 18/30, Train Loss: 0.2878, Train R2: 0.0887, Val Loss: 0.3498, Val R2: -0.0505\n",
      "Model saved as checkpoint_epoch_18.pth\n",
      "Epoch 19/30, Train Loss: 0.2787, Train R2: -0.3253, Val Loss: 0.3701, Val R2: 0.3690\n",
      "Epoch 20/30, Train Loss: 0.2916, Train R2: -0.0316, Val Loss: 0.4462, Val R2: 0.2679\n",
      "Epoch 21/30, Train Loss: 0.2826, Train R2: 0.4077, Val Loss: 0.3686, Val R2: 0.3125\n",
      "Epoch 22/30, Train Loss: 0.2219, Train R2: 0.5944, Val Loss: 0.3116, Val R2: 0.2988\n",
      "Model saved as checkpoint_epoch_22.pth\n",
      "Epoch 23/30, Train Loss: 0.1849, Train R2: 0.6284, Val Loss: 0.2764, Val R2: 0.2659\n",
      "Model saved as checkpoint_epoch_23.pth\n",
      "Epoch 24/30, Train Loss: 0.1619, Train R2: 0.5378, Val Loss: 0.2846, Val R2: -0.2617\n",
      "Epoch 25/30, Train Loss: 0.1569, Train R2: 0.6250, Val Loss: 0.2322, Val R2: 0.1055\n",
      "Model saved as checkpoint_epoch_25.pth\n",
      "Epoch 26/30, Train Loss: 0.1375, Train R2: 0.6087, Val Loss: 0.2025, Val R2: 0.2439\n",
      "Model saved as checkpoint_epoch_26.pth\n",
      "Epoch 27/30, Train Loss: 0.1088, Train R2: 0.7589, Val Loss: 0.1933, Val R2: 0.4863\n",
      "Model saved as checkpoint_epoch_27.pth\n",
      "Epoch 28/30, Train Loss: 0.0977, Train R2: 0.7788, Val Loss: 0.2008, Val R2: 0.4777\n",
      "Epoch 29/30, Train Loss: 0.1156, Train R2: 0.7248, Val Loss: 0.2338, Val R2: 0.3502\n",
      "Epoch 30/30, Train Loss: 0.1322, Train R2: 0.6327, Val Loss: 0.2306, Val R2: 0.2420\n",
      "Model saved as final_model.pth\n",
      "Training completed and final model saved.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loaders, val_loaders, device, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
