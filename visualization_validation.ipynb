{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.dataloader import create_dataloader, create_dataset\n",
    "from utils.utils import sorted_file_paths, find_latest_checkpoint\n",
    "\n",
    "from models.resnet import load_resnet_model, register_model_with_hook\n",
    "\n",
    "from visualization.lots import LOTS, calculate_activation_map\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "category_names = [\n",
    "    \"water\", \"trees\", \"grass\", \"flooded_vegetation\", \"crops\",\n",
    "    \"shrub_and_scrub\", \"built\", \"bare\", \"snow_and_ice\"\n",
    "]\n",
    "\n",
    "experiments = [\n",
    "    ['L2', './experiments/ex_2'],\n",
    "    ['Weighted sampling (alpha=0.5)', './experiments/ex_8'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_df(model, get_feature_maps, category_names, loader, device):\n",
    "    # Initialize storage structures\n",
    "    category_areas = {name: [] for name in category_names}\n",
    "    average_intensities = {name: [] for name in category_names}\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_locations = []\n",
    "\n",
    "    for data, location, labels in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predictions = model(data[:, :24, :, :])\n",
    "\n",
    "        # Flatten labels and predictions and store\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "        all_locations.extend([f\"{row[0]} + {row[1]}\" for row in location.cpu().numpy()])\n",
    "        all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "\n",
    "        for i in range(data.size(0)):\n",
    "            # Generate initial and adversarial images\n",
    "            imageinit = data[i, :24, :, :].unsqueeze(0)\n",
    "            imageadv,_ = LOTS(imageinit, 50, model, get_feature_maps, device, alpha=1)\n",
    "\n",
    "            # Calculate the activation map without normalization\n",
    "            activation_map = calculate_activation_map(imageinit.squeeze(), imageadv.squeeze(), filter_size=5, normalize=False)\n",
    "\n",
    "            # Process each category within the image\n",
    "            land_cover_mask = data[i, 24, :, :]  # Assuming the land cover mask is at channel index 24\n",
    "            for idx, category in enumerate(category_names):\n",
    "                category_mask = (land_cover_mask == idx).float()\n",
    "                category_area = category_mask.sum().item()\n",
    "                category_areas[category].append(category_area)\n",
    "\n",
    "                if category_mask.sum() > 0:\n",
    "                    average_intensity = (activation_map * category_mask).sum() / category_mask.sum()\n",
    "                    average_intensities[category].append(average_intensity.item())\n",
    "                else:\n",
    "                    average_intensities[category].append(np.nan)  # Handle no area case\n",
    "\n",
    "    # Convert results to DataFrames for better manipulation and visibility\n",
    "    intensities_df = pd.DataFrame(average_intensities)\n",
    "    areas_df = pd.DataFrame(category_areas)\n",
    "\n",
    "    # Concatenate the areas DataFrame with the intensities DataFrame\n",
    "    result_df = pd.concat([intensities_df, areas_df.add_suffix(\"_area\")], axis=1)\n",
    "\n",
    "    # Add location, label, and prediction data\n",
    "    result_df['Location'] = all_locations\n",
    "    result_df['Label'] = all_labels\n",
    "    result_df['Prediction'] = all_predictions\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted_file_paths('./data/test_records_with_land_cover/test')\n",
    "test_dataset = create_dataset(test_files, half= False)\n",
    "test_loader = create_dataloader(test_dataset, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/ex_2\\checkpoint_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [50:54<00:00, 92.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/ex_8\\checkpoint_epoch_17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [50:36<00:00, 92.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for experiment, path in experiments:\n",
    "    model = load_resnet_model()\n",
    "    checkpoint = find_latest_checkpoint(path)\n",
    "    print(checkpoint)\n",
    "    statedict = torch.load(checkpoint)\n",
    "    model.load_state_dict(statedict)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    get_feature_maps = register_model_with_hook(model)\n",
    "    df = calculate_activation_df(model, get_feature_maps, category_names, test_loader, device)\n",
    "    df.to_csv(f'./visualization_validation/{experiment}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
